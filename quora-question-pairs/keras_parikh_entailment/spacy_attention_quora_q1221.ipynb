{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, unicode_literals, print_function\n",
    "import spacy\n",
    "\n",
    "import plac\n",
    "from pathlib import Path\n",
    "import ujson as json\n",
    "import numpy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "\n",
    "from keras_decomposable_attention_quora import build_model\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_truncate=False\n",
    "gru_encode=False\n",
    "max_length=100\n",
    "nr_hidden=100\n",
    "dropout=0.2\n",
    "learn_rate=0.001\n",
    "batch_size=1024\n",
    "nr_epoch=100\n",
    "        \n",
    "shape = (max_length, nr_hidden, 1)\n",
    "\n",
    "settings = {\n",
    "    'lr': learn_rate,\n",
    "    'dropout': dropout,\n",
    "    'batch_size': batch_size,\n",
    "    'nr_epoch': nr_epoch,\n",
    "    'tree_truncate': tree_truncate,\n",
    "    'gru_encode': gru_encode\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loc = '/cinc/data/snli/train_1000/snli_1.0_train.jsonl'\n",
    "dev_loc   = '/cinc/data/snli/dev_1000/snli_1.0_dev.jsonl'\n",
    "\n",
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/quora-question-pairs/save_data/'\n",
    "model_path = '/cinc/data/quora-question-pairs/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "def read_snli(path):\n",
    "    texts1 = []\n",
    "    texts2 = []\n",
    "    labels = []\n",
    "    with open(path) as file_:\n",
    "        for line in file_:\n",
    "            eg = json.loads(line)\n",
    "            label = eg['gold_label']\n",
    "            if label == '-':\n",
    "                continue\n",
    "            texts1.append(eg['sentence1'])\n",
    "            texts2.append(eg['sentence2'])\n",
    "            labels.append(LABELS[label])\n",
    "    return texts1, texts2, to_categorical(numpy.asarray(labels, dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert nlp.path is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path + 'train/train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    }
   ],
   "source": [
    "#train_data = train_data[0:1000]\n",
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 143,   10,    4, 1130,   67, 1130, 4418,    5, 2570,   15,  998,\n",
       "         287,   15,   22,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 143,   10,    4, 1130,   67, 1130, 4418,    5, 2570,   15,  998,\n",
       "         287,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (train_data['question1'][0])\n",
    "print (train_data['question2'][0])\n",
    "ids_0 = get_word_ids(list(nlp.pipe((unicode(train_data['question1'][0]), unicode(train_data['question2'][0])))),\n",
    "             max_length=shape[0],\n",
    "             rnn_encode=settings['gru_encode'],\n",
    "             tree_truncate=settings['tree_truncate'])\n",
    "ids_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'What is the step by step guide to invest in share market in india?',\n",
       " u'What is the step by step guide to invest in share market?')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts1 = train_data['question1'].apply(lambda x: unicode(x))\n",
    "all_texts2 = train_data['question2'].apply(lambda x: unicode(x))\n",
    "all_texts1[0], all_texts2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs_all = []\n",
    "for texts in (all_texts1, all_texts2):\n",
    "    #print (texts)\n",
    "    Xs_all.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                     max_length=shape[0],\n",
    "                     rnn_encode=settings['gru_encode'],\n",
    "                     tree_truncate=settings['tree_truncate']))\n",
    "X1_all, X2_all = Xs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all = train_data['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 100), (404290, 100), (404290,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_all.shape, X2_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q1 <-> q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((808580, 100), (808580, 100), (808580,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_all_temp = np.vstack((X1_all, X2_all))\n",
    "X2_all_temp = np.vstack((X2_all, X1_all))\n",
    "y_all_temp = np.hstack((y_all, y_all))\n",
    "\n",
    "X1_all_temp.shape, X2_all_temp.shape, y_all_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((808580, 100), (808580, 100), (808580,), 808580)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_all = X1_all_temp\n",
    "X2_all = X2_all_temp\n",
    "y_all = y_all_temp\n",
    "\n",
    "nb_samples = train_data.shape[0] * 2\n",
    "\n",
    "X1_all.shape, X2_all.shape, y_all.shape, nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "save_array(save_path + 'X1_all', X1_all)\n",
    "save_array(save_path + 'X2_all', X2_all)\n",
    "save_array(save_path +  'y_all',  y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((808580, 100), (808580, 100), (808580,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load back\n",
    "X1_all = load_array(save_path + 'X1_all')\n",
    "X2_all = load_array(save_path + 'X2_all')\n",
    "y_all  = load_array(save_path +  'y_all')\n",
    "X1_all.shape, X2_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(nb_samples) < 0.8\n",
    "#msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((647100, 100),\n",
       " (647100, 100),\n",
       " (647100,),\n",
       " (161480, 100),\n",
       " (161480, 100),\n",
       " (161480,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train = X1_all[msk]\n",
    "X1_valid = X1_all[~msk]\n",
    "\n",
    "X2_train = X2_all[msk]\n",
    "X2_valid = X2_all[~msk]\n",
    "\n",
    "y_train = y_all[msk]\n",
    "y_valid = y_all[~msk]\n",
    "\n",
    "(X1_train.shape, X2_train.shape, y_train.shape, X1_valid.shape, X2_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "save_array(save_path + 'X1_train', X1_train)\n",
    "save_array(save_path + 'X2_train', X2_train)\n",
    "save_array(save_path +  'y_train',  y_train)\n",
    "\n",
    "save_array(save_path + 'X1_valid', X1_valid)\n",
    "save_array(save_path + 'X2_valid', X2_valid)\n",
    "save_array(save_path +  'y_valid',  y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647100, 100) (647100, 100) (647100,)\n",
      "(161480, 100) (161480, 100) (161480,)\n"
     ]
    }
   ],
   "source": [
    "# load back\n",
    "X1_train = load_array(save_path + 'X1_train')\n",
    "X2_train = load_array(save_path + 'X2_train')\n",
    "y_train  = load_array(save_path +  'y_train')\n",
    "\n",
    "X1_valid = load_array(save_path + 'X1_valid')\n",
    "X2_valid = load_array(save_path + 'X2_valid')\n",
    "y_valid  = load_array(save_path +  'y_valid')\n",
    "\n",
    "print (X1_train.shape, X2_train.shape, y_train.shape)\n",
    "print (X1_valid.shape, X2_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(get_embeddings(nlp.vocab), shape, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ModelCheckpoint(model_path + 'spacy_attention_quora_q1221.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 647100 samples, validate on 161480 samples\n",
      "Epoch 1/100\n",
      "375s - loss: 0.3937 - acc: 0.8099 - val_loss: 0.4092 - val_acc: 0.7994\n",
      "Epoch 2/100\n",
      "383s - loss: 0.3869 - acc: 0.8145 - val_loss: 0.3963 - val_acc: 0.8074\n",
      "Epoch 3/100\n",
      "384s - loss: 0.3826 - acc: 0.8175 - val_loss: 0.3962 - val_acc: 0.8061\n",
      "Epoch 4/100\n",
      "374s - loss: 0.3799 - acc: 0.8181 - val_loss: 0.4133 - val_acc: 0.7944\n",
      "Epoch 5/100\n",
      "374s - loss: 0.3772 - acc: 0.8202 - val_loss: 0.4026 - val_acc: 0.8009\n",
      "Epoch 6/100\n",
      "383s - loss: 0.3749 - acc: 0.8214 - val_loss: 0.3953 - val_acc: 0.8022\n",
      "Epoch 7/100\n",
      "383s - loss: 0.3726 - acc: 0.8232 - val_loss: 0.3875 - val_acc: 0.8098\n",
      "Epoch 8/100\n",
      "373s - loss: 0.3711 - acc: 0.8242 - val_loss: 0.3896 - val_acc: 0.8079\n",
      "Epoch 9/100\n",
      "373s - loss: 0.3687 - acc: 0.8251 - val_loss: 0.3899 - val_acc: 0.8080\n",
      "Epoch 10/100\n",
      "373s - loss: 0.3675 - acc: 0.8255 - val_loss: 0.4031 - val_acc: 0.7983\n",
      "Epoch 11/100\n",
      "383s - loss: 0.3659 - acc: 0.8267 - val_loss: 0.3804 - val_acc: 0.8134\n",
      "Epoch 12/100\n",
      "374s - loss: 0.3651 - acc: 0.8270 - val_loss: 0.3987 - val_acc: 0.8006\n",
      "Epoch 13/100\n",
      "374s - loss: 0.3636 - acc: 0.8283 - val_loss: 0.3839 - val_acc: 0.8120\n",
      "Epoch 14/100\n",
      "383s - loss: 0.3623 - acc: 0.8289 - val_loss: 0.3768 - val_acc: 0.8177\n",
      "Epoch 15/100\n",
      "374s - loss: 0.3605 - acc: 0.8302 - val_loss: 0.3845 - val_acc: 0.8120\n",
      "Epoch 16/100\n",
      "373s - loss: 0.3593 - acc: 0.8308 - val_loss: 0.3895 - val_acc: 0.8086\n",
      "Epoch 17/100\n",
      "372s - loss: 0.3582 - acc: 0.8314 - val_loss: 0.3974 - val_acc: 0.8038\n",
      "Epoch 18/100\n",
      "383s - loss: 0.3569 - acc: 0.8320 - val_loss: 0.3752 - val_acc: 0.8182\n",
      "Epoch 19/100\n",
      "374s - loss: 0.3570 - acc: 0.8320 - val_loss: 0.3883 - val_acc: 0.8099\n",
      "Epoch 20/100\n",
      "374s - loss: 0.3548 - acc: 0.8334 - val_loss: 0.3848 - val_acc: 0.8119\n",
      "Epoch 21/100\n",
      "373s - loss: 0.3537 - acc: 0.8337 - val_loss: 0.3893 - val_acc: 0.8091\n",
      "Epoch 22/100\n",
      "371s - loss: 0.3529 - acc: 0.8346 - val_loss: 0.3767 - val_acc: 0.8187\n",
      "Epoch 23/100\n",
      "372s - loss: 0.3527 - acc: 0.8343 - val_loss: 0.3870 - val_acc: 0.8118\n",
      "Epoch 24/100\n",
      "381s - loss: 0.3517 - acc: 0.8345 - val_loss: 0.3670 - val_acc: 0.8270\n",
      "Epoch 25/100\n",
      "372s - loss: 0.3511 - acc: 0.8351 - val_loss: 0.4110 - val_acc: 0.7988\n",
      "Epoch 26/100\n",
      "372s - loss: 0.3506 - acc: 0.8356 - val_loss: 0.3839 - val_acc: 0.8121\n",
      "Epoch 27/100\n",
      "372s - loss: 0.3494 - acc: 0.8361 - val_loss: 0.3831 - val_acc: 0.8117\n",
      "Epoch 28/100\n",
      "371s - loss: 0.3486 - acc: 0.8367 - val_loss: 0.3815 - val_acc: 0.8153\n",
      "Epoch 29/100\n",
      "371s - loss: 0.3473 - acc: 0.8373 - val_loss: 0.3778 - val_acc: 0.8164\n",
      "Epoch 30/100\n",
      "371s - loss: 0.3472 - acc: 0.8382 - val_loss: 0.3842 - val_acc: 0.8137\n",
      "Epoch 31/100\n",
      "371s - loss: 0.3464 - acc: 0.8377 - val_loss: 0.3918 - val_acc: 0.8074\n",
      "Epoch 32/100\n",
      "371s - loss: 0.3455 - acc: 0.8382 - val_loss: 0.3831 - val_acc: 0.8132\n",
      "Epoch 33/100\n",
      "371s - loss: 0.3457 - acc: 0.8381 - val_loss: 0.3902 - val_acc: 0.8075\n",
      "Epoch 34/100\n",
      "371s - loss: 0.3447 - acc: 0.8387 - val_loss: 0.3810 - val_acc: 0.8160\n",
      "Epoch 35/100\n",
      "372s - loss: 0.3433 - acc: 0.8400 - val_loss: 0.3901 - val_acc: 0.8103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27416f9250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X1_train, X2_train],\n",
    "    y_train,\n",
    "    validation_data=([X1_valid, X2_valid], y_valid),\n",
    "    nb_epoch=settings['nr_epoch'],\n",
    "    batch_size=settings['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(save_path + 'model/spacy_attention_quora_q1221.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path + 'spacy_attention_quora_q1221.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pred = model.predict([X1_all[0:10], X2_all[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    What is the step by step guide to invest in sh...\n",
       " 1    What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       " 2    How can I increase the speed of my internet co...\n",
       " Name: question1, dtype: object,\n",
       " 0    What is the step by step guide to invest in sh...\n",
       " 1    What would happen if the Indian government sto...\n",
       " 2    How can Internet speed be increased by hacking...\n",
       " Name: question2, dtype: object,\n",
       " array([[ 0.14724822],\n",
       "        [ 0.34619609],\n",
       "        [ 0.66504312]], dtype=float32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts1[0:3], all_texts2[0:3], all_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valid_pred[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_ids(list(nlp.pipe(('I am ok.', 'I am good'))),\n",
    "             max_length=shape[0],\n",
    "             rnn_encode=settings['gru_encode'],\n",
    "             tree_truncate=settings['tree_truncate']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + 'test/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data = test_data[0:82]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_batch(df_data, start, end):\n",
    "    test_texts1 = test_data['question1'][start:end].apply(lambda x: unicode(x))\n",
    "    test_texts2 = test_data['question2'][start:end].apply(lambda x: unicode(x))\n",
    "\n",
    "    Xs_test = []\n",
    "    for texts in (test_texts1, test_texts2):\n",
    "        #print (texts)\n",
    "        Xs_test.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                         max_length=shape[0],\n",
    "                         rnn_encode=settings['gru_encode'],\n",
    "                         tree_truncate=settings['tree_truncate']))\n",
    "    test_X1, test_X2 = Xs_test\n",
    "\n",
    "    return model.predict([test_X1, test_X2], batch_size=1024)\n",
    "\n",
    "a = predict_batch(test_data, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [30:33<00:00,  6.88s/it]\n"
     ]
    }
   ],
   "source": [
    "#test_pred = []\n",
    "batch_size = 10000\n",
    "for i in tqdm(range(int(test_data.shape[0] / batch_size)+1)):\n",
    "    start = i*batch_size\n",
    "    end   = min((i+1)*batch_size, test_data.shape[0])\n",
    "    #print ('proceccinng: ', i, start, end)\n",
    "    batch_pred = predict_batch(test_data, start, end)\n",
    "    if (i == 0):\n",
    "        test_pred = batch_pred\n",
    "    else:\n",
    "        test_pred = np.vstack( (test_pred, batch_pred) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 2345796)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape[0], len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20613281], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')\n",
    "print (df_submission.shape)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.206133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.286344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.490187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.153228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.616452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.206133\n",
       "1        1      0.286344\n",
       "2        2      0.490187\n",
       "3        3      0.153228\n",
       "4        4      0.616452"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['is_duplicate'] = test_pred\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/spacy_attention_quora_q1221_20170522.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
