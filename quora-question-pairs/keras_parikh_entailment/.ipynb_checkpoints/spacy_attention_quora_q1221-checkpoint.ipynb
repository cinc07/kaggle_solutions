{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, unicode_literals, print_function\n",
    "import spacy\n",
    "\n",
    "import plac\n",
    "from pathlib import Path\n",
    "import ujson as json\n",
    "import numpy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "\n",
    "from keras_decomposable_attention_quora import build_model\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_truncate=False\n",
    "gru_encode=False\n",
    "max_length=100\n",
    "nr_hidden=100\n",
    "dropout=0.2\n",
    "learn_rate=0.001\n",
    "batch_size=100\n",
    "nr_epoch=100\n",
    "        \n",
    "shape = (max_length, nr_hidden, 1)\n",
    "\n",
    "settings = {\n",
    "    'lr': learn_rate,\n",
    "    'dropout': dropout,\n",
    "    'batch_size': batch_size,\n",
    "    'nr_epoch': nr_epoch,\n",
    "    'tree_truncate': tree_truncate,\n",
    "    'gru_encode': gru_encode\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loc = '/cinc/data/snli/train_1000/snli_1.0_train.jsonl'\n",
    "dev_loc   = '/cinc/data/snli/dev_1000/snli_1.0_dev.jsonl'\n",
    "\n",
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/quora-question-pairs/save_data/'\n",
    "model_path = '/cinc/data/quora-question-pairs/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "def read_snli(path):\n",
    "    texts1 = []\n",
    "    texts2 = []\n",
    "    labels = []\n",
    "    with open(path) as file_:\n",
    "        for line in file_:\n",
    "            eg = json.loads(line)\n",
    "            label = eg['gold_label']\n",
    "            if label == '-':\n",
    "                continue\n",
    "            texts1.append(eg['sentence1'])\n",
    "            texts2.append(eg['sentence2'])\n",
    "            labels.append(LABELS[label])\n",
    "    return texts1, texts2, to_categorical(numpy.asarray(labels, dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert nlp.path is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path + 'train/train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6)\n"
     ]
    }
   ],
   "source": [
    "#train_data = train_data[0:1000]\n",
    "print (train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n",
      "What is the step by step guide to invest in share market?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 143,   10,    4, 1130,   67, 1130, 4418,    5, 2570,   15,  998,\n",
       "         287,   15,   22,    1,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 143,   10,    4, 1130,   67, 1130, 4418,    5, 2570,   15,  998,\n",
       "         287,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (train_data['question1'][0])\n",
    "print (train_data['question2'][0])\n",
    "ids_0 = get_word_ids(list(nlp.pipe((unicode(train_data['question1'][0]), unicode(train_data['question2'][0])))),\n",
    "             max_length=shape[0],\n",
    "             rnn_encode=settings['gru_encode'],\n",
    "             tree_truncate=settings['tree_truncate'])\n",
    "ids_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'What is the step by step guide to invest in share market in india?',\n",
       " u'What is the step by step guide to invest in share market?')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts1 = train_data['question1'].apply(lambda x: unicode(x))\n",
    "all_texts2 = train_data['question2'].apply(lambda x: unicode(x))\n",
    "all_texts1[0], all_texts2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_all = []\n",
    "for texts in (all_texts1, all_texts2):\n",
    "    #print (texts)\n",
    "    Xs_all.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                     max_length=shape[0],\n",
    "                     rnn_encode=settings['gru_encode'],\n",
    "                     tree_truncate=settings['tree_truncate']))\n",
    "X1_all, X2_all = Xs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all = train_data['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 100), (404290, 100), (404290,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_all.shape, X2_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "save_array(save_path + 'X1_all', X1_all)\n",
    "save_array(save_path + 'X2_all', X2_all)\n",
    "save_array(save_path +  'y_all',  y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 100), (404290, 100), (404290,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load back\n",
    "X1_all = load_array(save_path + 'X1_all')\n",
    "X2_all = load_array(save_path + 'X2_all')\n",
    "y_all  = load_array(save_path +  'y_all')\n",
    "X1_all.shape, X2_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q1 <-> q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_all_temp = np.vstack((X1_all, X2_all))\n",
    "X2_all_temp = np.vstack((X2_all, X1_all))\n",
    "y_all_temp = np.hstack((y_all, y_all))\n",
    "\n",
    "X1_all_temp.shape, X2_all_temp.shape, y_all_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_all = X1_all_temp\n",
    "X2_all = X2_all_temp\n",
    "y_all = y_all_temp\n",
    "\n",
    "nb_samples = train_data.shape[0] * 2\n",
    "\n",
    "X1_all.shape, X2_all.shape, y_all.shape, nb_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(nb_samples) < 0.8\n",
    "#msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323060, 100), (323060, 100), (323060,), (81230, 100), (81230, 100), (81230,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train = X1_all[msk]\n",
    "X1_valid = X1_all[~msk]\n",
    "\n",
    "X2_train = X2_all[msk]\n",
    "X2_valid = X2_all[~msk]\n",
    "\n",
    "y_train = y_all[msk]\n",
    "y_valid = y_all[~msk]\n",
    "\n",
    "(X1_train.shape, X2_train.shape, y_train.shape, X1_valid.shape, X2_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "save_array(save_path + 'X1_train', X1_train)\n",
    "save_array(save_path + 'X2_train', X2_train)\n",
    "save_array(save_path +  'y_train',  y_train)\n",
    "\n",
    "save_array(save_path + 'X1_valid', X1_valid)\n",
    "save_array(save_path + 'X2_valid', X2_valid)\n",
    "save_array(save_path +  'y_valid',  y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323060, 100) (323060, 100) (323060,)\n",
      "(81230, 100) (81230, 100) (81230,)\n"
     ]
    }
   ],
   "source": [
    "# load back\n",
    "X1_train = load_array(save_path + 'X1_train')\n",
    "X2_train = load_array(save_path + 'X2_train')\n",
    "y_train  = load_array(save_path +  'y_train')\n",
    "\n",
    "X1_valid = load_array(save_path + 'X1_valid')\n",
    "X2_valid = load_array(save_path + 'X2_valid')\n",
    "y_valid  = load_array(save_path +  'y_valid')\n",
    "\n",
    "print (X1_train.shape, X2_train.shape, y_train.shape)\n",
    "print (X1_valid.shape, X2_valid.shape, y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(get_embeddings(nlp.vocab), shape, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    ModelCheckpoint(model_path + 'spacy_attention_quora.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323060 samples, validate on 81230 samples\n",
      "Epoch 1/100\n",
      "429s - loss: 0.5264 - acc: 0.7291 - val_loss: 0.5079 - val_acc: 0.7427\n",
      "Epoch 2/100\n",
      "419s - loss: 0.4670 - acc: 0.7668 - val_loss: 0.5485 - val_acc: 0.7144\n",
      "Epoch 3/100\n",
      "420s - loss: 0.4451 - acc: 0.7793 - val_loss: 0.4781 - val_acc: 0.7509\n",
      "Epoch 4/100\n",
      "415s - loss: 0.4335 - acc: 0.7864 - val_loss: 0.4873 - val_acc: 0.7467\n",
      "Epoch 5/100\n",
      "415s - loss: 0.4252 - acc: 0.7909 - val_loss: 0.4863 - val_acc: 0.7523\n",
      "Epoch 6/100\n",
      "426s - loss: 0.4188 - acc: 0.7951 - val_loss: 0.4761 - val_acc: 0.7573\n",
      "Epoch 7/100\n",
      "424s - loss: 0.4148 - acc: 0.7980 - val_loss: 0.4647 - val_acc: 0.7609\n",
      "Epoch 8/100\n",
      "428s - loss: 0.4102 - acc: 0.8007 - val_loss: 0.4479 - val_acc: 0.7662\n",
      "Epoch 9/100\n",
      "415s - loss: 0.4062 - acc: 0.8029 - val_loss: 0.4685 - val_acc: 0.7588\n",
      "Epoch 10/100\n",
      "424s - loss: 0.4037 - acc: 0.8053 - val_loss: 0.4441 - val_acc: 0.7727\n",
      "Epoch 11/100\n",
      "416s - loss: 0.4029 - acc: 0.8055 - val_loss: 0.4608 - val_acc: 0.7674\n",
      "Epoch 12/100\n",
      "415s - loss: 0.4005 - acc: 0.8063 - val_loss: 0.4497 - val_acc: 0.7688\n",
      "Epoch 13/100\n",
      "424s - loss: 0.3995 - acc: 0.8067 - val_loss: 0.4323 - val_acc: 0.7820\n",
      "Epoch 14/100\n",
      "416s - loss: 0.3997 - acc: 0.8069 - val_loss: 0.4532 - val_acc: 0.7678\n",
      "Epoch 15/100\n",
      "421s - loss: 0.4000 - acc: 0.8069 - val_loss: 0.5340 - val_acc: 0.7377\n",
      "Epoch 16/100\n",
      "421s - loss: 0.4003 - acc: 0.8065 - val_loss: 0.4344 - val_acc: 0.7764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4d79f4dd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X1_train, X2_train],\n",
    "    y_train,\n",
    "    validation_data=([X1_valid, X2_valid], y_valid),\n",
    "    nb_epoch=settings['nr_epoch'],\n",
    "    batch_size=settings['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(save_path + 'model/spacy_attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_path + 'spacy_attention_quora.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_pred = model.predict([X1_all[0:10], X2_all[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    What is the step by step guide to invest in sh...\n",
       " 1    What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       " 2    How can I increase the speed of my internet co...\n",
       " Name: question1, dtype: object,\n",
       " 0    What is the step by step guide to invest in sh...\n",
       " 1    What would happen if the Indian government sto...\n",
       " 2    How can Internet speed be increased by hacking...\n",
       " Name: question2, dtype: object,\n",
       " array([[ 0.11565141],\n",
       "        [ 0.14543147],\n",
       "        [ 0.33632338]], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts1[0:3], all_texts2[0:3], all_pred[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valid_pred[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_ids(list(nlp.pipe(('I am ok.', 'I am good'))),\n",
    "             max_length=shape[0],\n",
    "             rnn_encode=settings['gru_encode'],\n",
    "             tree_truncate=settings['tree_truncate']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + 'test/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data = test_data[0:82]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_batch(df_data, start, end):\n",
    "    test_texts1 = test_data['question1'][start:end].apply(lambda x: unicode(x))\n",
    "    test_texts2 = test_data['question2'][start:end].apply(lambda x: unicode(x))\n",
    "\n",
    "    Xs_test = []\n",
    "    for texts in (test_texts1, test_texts2):\n",
    "        #print (texts)\n",
    "        Xs_test.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                         max_length=shape[0],\n",
    "                         rnn_encode=settings['gru_encode'],\n",
    "                         tree_truncate=settings['tree_truncate']))\n",
    "    test_X1, test_X2 = Xs_test\n",
    "\n",
    "    return model.predict([test_X1, test_X2], batch_size=1024)\n",
    "\n",
    "a = predict_batch(test_data, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [31:39<00:00,  7.14s/it]\n"
     ]
    }
   ],
   "source": [
    "#test_pred = []\n",
    "batch_size = 10000\n",
    "for i in tqdm(range(int(test_data.shape[0] / batch_size)+1)):\n",
    "    start = i*batch_size\n",
    "    end   = min((i+1)*batch_size, test_data.shape[0])\n",
    "    #print ('proceccinng: ', i, start, end)\n",
    "    batch_pred = predict_batch(test_data, start, end)\n",
    "    if (i == 0):\n",
    "        test_pred = batch_pred\n",
    "    else:\n",
    "        test_pred = np.vstack( (test_pred, batch_pred) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 2345796)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape[0], len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21598335], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')\n",
    "print (df_submission.shape)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.215983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.089754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.629537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.328479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.632163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.215983\n",
       "1        1      0.089754\n",
       "2        2      0.629537\n",
       "3        3      0.328479\n",
       "4        4      0.632163"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['is_duplicate'] = test_pred\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/spacy_attention_quora_20170511.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
