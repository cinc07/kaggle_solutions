{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, unicode_literals, print_function\n",
    "import spacy\n",
    "\n",
    "import plac\n",
    "from pathlib import Path\n",
    "import ujson as json\n",
    "import numpy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from spacy_hook import get_embeddings, get_word_ids\n",
    "from spacy_hook import create_similarity_pipeline\n",
    "\n",
    "from keras_decomposable_attention import build_model\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "#import sys\n",
    "#reload(sys)  \n",
    "#sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_truncate=False\n",
    "gru_encode=False\n",
    "max_length=100\n",
    "nr_hidden=100\n",
    "dropout=0.2\n",
    "learn_rate=0.001\n",
    "batch_size=100\n",
    "nr_epoch=100\n",
    "        \n",
    "shape = (max_length, nr_hidden, 3)\n",
    "\n",
    "settings = {\n",
    "    'lr': learn_rate,\n",
    "    'dropout': dropout,\n",
    "    'batch_size': batch_size,\n",
    "    'nr_epoch': nr_epoch,\n",
    "    'tree_truncate': tree_truncate,\n",
    "    'gru_encode': gru_encode\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_loc = '/cinc/data/snli/train_1000/snli_1.0_train.jsonl'\n",
    "#dev_loc   = '/cinc/data/snli/dev_1000/snli_1.0_dev.jsonl'\n",
    "\n",
    "train_loc = '/cinc/data/snli/train/snli_1.0_train.jsonl'\n",
    "dev_loc   = '/cinc/data/snli/dev/snli_1.0_dev.jsonl'\n",
    "\n",
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/snli/save_data/'\n",
    "model_path = '/cinc/data/snli/save_data/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "def read_snli(path):\n",
    "    texts1 = []\n",
    "    texts2 = []\n",
    "    labels = []\n",
    "    with open(path) as file_:\n",
    "        for line in file_:\n",
    "            eg = json.loads(line)\n",
    "            label = eg['gold_label']\n",
    "            if label == '-':\n",
    "                continue\n",
    "            texts1.append(eg['sentence1'])\n",
    "            texts2.append(eg['sentence2'])\n",
    "            labels.append(LABELS[label])\n",
    "    return texts1, texts2, to_categorical(numpy.asarray(labels, dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert nlp.path is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_texts1, train_texts2, train_labels = read_snli(train_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549367 549367 549367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'A person on a horse jumps over a broken down airplane.',\n",
       " u'A person is training his horse for a competition.',\n",
       " array([ 0.,  0.,  1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len(train_texts1), len(train_texts2), len(train_labels))\n",
    "train_texts1[0], train_texts2[0], train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_texts1, dev_texts2, dev_labels = read_snli(dev_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9842 9842 9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'Two women are embracing while holding to go packages.',\n",
       " u'The sisters are hugging goodbye while holding to go packages after just eating lunch.',\n",
       " array([ 0.,  0.,  1.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len(dev_texts1), len(dev_texts2), len(dev_labels))\n",
    "dev_texts1[0], dev_texts2[0], dev_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = []\n",
    "for texts in (train_texts1, train_texts2, dev_texts1, dev_texts2):\n",
    "    #print (texts)\n",
    "    Xs.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                     max_length=shape[0],\n",
    "                     rnn_encode=settings['gru_encode'],\n",
    "                     tree_truncate=settings['tree_truncate']))\n",
    "train_X1, train_X2, dev_X1, dev_X2 = Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((549367, 100), (549367, 100), (9842, 100), (9842, 100))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X1.shape, train_X2.shape, dev_X1.shape, dev_X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "save_array(save_path + 'train_X1', train_X1)\n",
    "save_array(save_path + 'train_X2', train_X2)\n",
    "save_array(save_path + 'train_labels', train_labels)\n",
    "\n",
    "save_array(save_path + 'dev_X1', dev_X1)\n",
    "save_array(save_path + 'dev_X2', dev_X2)\n",
    "save_array(save_path + 'dev_labels', dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load back\n",
    "train_X1 = load_array(save_path + 'train_X1')\n",
    "train_X2 = load_array(save_path + 'train_X2')\n",
    "train_labels = load_array(save_path + 'train_labels')\n",
    "\n",
    "dev_X1 = load_array(save_path + 'dev_X1')\n",
    "dev_X2 = load_array(save_path + 'dev_X2')\n",
    "dev_labels = load_array(save_path + 'dev_labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model(get_embeddings(nlp.vocab), shape, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    ModelCheckpoint(model_path + 'spacy_attention_snli.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 549367 samples, validate on 9842 samples\n",
      "Epoch 1/100\n",
      "674s - loss: 0.7730 - acc: 0.6607 - val_loss: 0.6204 - val_acc: 0.7465\n",
      "Epoch 2/100\n",
      "683s - loss: 0.6702 - acc: 0.7210 - val_loss: 0.6172 - val_acc: 0.7466\n",
      "Epoch 3/100\n",
      "681s - loss: 0.6488 - acc: 0.7321 - val_loss: 0.5911 - val_acc: 0.7597\n",
      "Epoch 4/100\n",
      "685s - loss: 0.6359 - acc: 0.7378 - val_loss: 0.5884 - val_acc: 0.7668\n",
      "Epoch 5/100\n",
      "687s - loss: 0.6265 - acc: 0.7421 - val_loss: 0.5701 - val_acc: 0.7677\n",
      "Epoch 6/100\n",
      "686s - loss: 0.6202 - acc: 0.7449 - val_loss: 0.5552 - val_acc: 0.7748\n",
      "Epoch 7/100\n",
      "687s - loss: 0.6146 - acc: 0.7477 - val_loss: 0.5471 - val_acc: 0.7776\n",
      "Epoch 8/100\n",
      "678s - loss: 0.6093 - acc: 0.7506 - val_loss: 0.5477 - val_acc: 0.7810\n",
      "Epoch 9/100\n",
      "687s - loss: 0.6081 - acc: 0.7509 - val_loss: 0.5467 - val_acc: 0.7779\n",
      "Epoch 10/100\n",
      "680s - loss: 0.6051 - acc: 0.7518 - val_loss: 0.5463 - val_acc: 0.7797\n",
      "Epoch 11/100\n",
      "669s - loss: 0.6035 - acc: 0.7523 - val_loss: 0.5493 - val_acc: 0.7780\n",
      "Epoch 12/100\n",
      "676s - loss: 0.6031 - acc: 0.7532 - val_loss: 0.5452 - val_acc: 0.7793\n",
      "Epoch 13/100\n",
      "683s - loss: 0.6019 - acc: 0.7534 - val_loss: 0.5413 - val_acc: 0.7806\n",
      "Epoch 14/100\n",
      "677s - loss: 0.6015 - acc: 0.7534 - val_loss: 0.5388 - val_acc: 0.7807\n",
      "Epoch 15/100\n",
      "679s - loss: 0.6018 - acc: 0.7534 - val_loss: 0.5388 - val_acc: 0.7779\n",
      "Epoch 16/100\n",
      "667s - loss: 0.6030 - acc: 0.7523 - val_loss: 0.5467 - val_acc: 0.7774\n",
      "Epoch 17/100\n",
      "668s - loss: 0.6038 - acc: 0.7518 - val_loss: 0.5433 - val_acc: 0.7804\n",
      "Epoch 18/100\n",
      "672s - loss: 0.6044 - acc: 0.7513 - val_loss: 0.5466 - val_acc: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f33b2b850>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [train_X1, train_X2],\n",
    "    train_labels,\n",
    "    validation_data=([dev_X1, dev_X2], dev_labels),\n",
    "    nb_epoch=settings['nr_epoch'],\n",
    "    batch_size=settings['batch_size'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(save_path + 'model/spacy_attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(save_path + 'model/spacy_attention_snli.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_pred = model.predict([dev_X1, dev_X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9842, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95089561,  0.02457028,  0.02453408], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_texts1[1], dev_texts2[1], valid_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valid_pred[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_ids(list(nlp.pipe(('I am ok.', 'I am good'))),\n",
    "             max_length=shape[0],\n",
    "             rnn_encode=settings['gru_encode'],\n",
    "             tree_truncate=settings['tree_truncate']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(path + 'test/test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "#test_data = test_data[0:82]\n",
    "print (test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_batch(df_data, start, end):\n",
    "    test_texts1 = test_data['question1'][start:end].apply(lambda x: unicode(x))\n",
    "    test_texts2 = test_data['question2'][start:end].apply(lambda x: unicode(x))\n",
    "\n",
    "    Xs_test = []\n",
    "    for texts in (test_texts1, test_texts2):\n",
    "        #print (texts)\n",
    "        Xs_test.append(get_word_ids(list(nlp.pipe(texts, n_threads=20, batch_size=20000)),\n",
    "                         max_length=shape[0],\n",
    "                         rnn_encode=settings['gru_encode'],\n",
    "                         tree_truncate=settings['tree_truncate']))\n",
    "    test_X1, test_X2 = Xs_test\n",
    "\n",
    "    return model.predict([test_X1, test_X2], batch_size=1024)\n",
    "\n",
    "a = predict_batch(test_data, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [59:36<00:00, 13.25s/it]\n"
     ]
    }
   ],
   "source": [
    "#test_pred = []\n",
    "batch_size = 10000\n",
    "for i in tqdm(range(int(test_data.shape[0] / batch_size)+1)):\n",
    "    start = i*batch_size\n",
    "    end   = min((i+1)*batch_size, test_data.shape[0])\n",
    "    #print ('proceccinng: ', i, start, end)\n",
    "    batch_pred = predict_batch(test_data, start, end)\n",
    "    if (i == 0):\n",
    "        test_pred = batch_pred\n",
    "    else:\n",
    "        test_pred = np.vstack( (test_pred, batch_pred) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 2345796)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape[0], len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15557578,  0.82303774,  0.94565886, ...,  0.31952131,\n",
       "        0.75785476,  0.42257354], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')\n",
    "print (df_submission.shape)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.155576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.823038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.945659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.754880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.756286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.155576\n",
       "1        1      0.823038\n",
       "2        2      0.945659\n",
       "3        3      0.754880\n",
       "4        4      0.756286"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['is_duplicate'] = test_pred[:,0]\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/spacy_attention_snli_20170512.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
