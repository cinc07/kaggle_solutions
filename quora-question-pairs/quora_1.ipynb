{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import csv\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/quora-question-pairs/save_data/'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "#    if stem_words:\n",
    "#        text = text.split()\n",
    "#        stemmer = SnowballStemmer('english')\n",
    "#        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "#        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read training text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv(path + 'train/train-sample.csv')\n",
    "train_data = pd.read_csv(path + 'train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = train_data.shape[0]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'what is the story of kohinoor koh - i - noor diamond ')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['question1'][1], text_to_wordlist(str(train_data['question1'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text_1 = [None]*train_data.shape[0]\n",
    "train_text_2 = [None]*train_data.shape[0]\n",
    "train_labels = [None]*train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(train_data.shape[0]):\n",
    "    train_text_1[i] = (text_to_wordlist(str(train_data['question1'][i]), remove_stopwords=True))\n",
    "    train_text_2[i] = (text_to_wordlist(str(train_data['question2'][i]), remove_stopwords=True))\n",
    "    train_labels[i] = (train_data['is_duplicate'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290,\n",
       " 404290,\n",
       " 404290,\n",
       " 'step step guide invest share market india ',\n",
       " 'step step guide invest share market ',\n",
       " 0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text_1), len(train_text_2), len(train_labels), train_text_1[0], train_text_2[0], train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808580"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_data['question1']) + list(train_data['question2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(path + 'test/test.csv')\n",
    "print test_data.shape[0]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_text_1 = [None] * test_data.shape[0]\n",
    "test_text_2 = [None] * test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(test_data.shape[0]):\n",
    "    test_text_1[i] = text_to_wordlist(str(test_data['question1'][i]), remove_stopwords=True)\n",
    "    test_text_2[i] = text_to_wordlist(str(test_data['question2'][i]), remove_stopwords=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796,\n",
       " 2345796,\n",
       " 'surface pro 4 compare ipad pro ',\n",
       " 'microsoft choose core m3 core i3 home surface pro 4 ')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text_1), len(test_text_2), test_text_1[0], test_text_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nb_words=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_text_1 + train_text_2 + test_text_1 + test_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['what']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sequence_1 = tokenizer.texts_to_sequences(train_text_1)\n",
    "train_sequence_2 = tokenizer.texts_to_sequences(train_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sequence_1  = tokenizer.texts_to_sequences(test_text_1)\n",
    "test_sequence_2  = tokenizer.texts_to_sequences(test_text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 118, 118, 119)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_length(text_list):\n",
    "    max_len = 0\n",
    "    for text in text_list:\n",
    "        if (len(text) > max_len):\n",
    "            max_len = len(text)\n",
    "    return max_len\n",
    "\n",
    "max_length(train_sequence_1), max_length(train_sequence_2), max_length(test_sequence_1), max_length(test_sequence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1183, 1183, 2854, 499, 685, 289, 3],\n",
       " [1183, 1183, 2854, 499, 685, 289],\n",
       " [1967, 753, 103, 286, 1586, 753],\n",
       " [655, 336, 837, 17733, 837, 4199, 172, 1967, 753, 103])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence_1[0], train_sequence_2[0], test_sequence_1[0], test_sequence_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sequence_1 = pad_sequences(train_sequence_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "train_sequence_2 = pad_sequences(train_sequence_2, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sequence_1 = pad_sequences(test_sequence_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_sequence_2 = pad_sequences(test_sequence_2, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 30), (404290, 30), (2345796, 30), (2345796, 30))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence_1.shape, train_sequence_2.shape, test_sequence_1.shape, test_sequence_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(save_path + 'train_sequence_1', train_sequence_1)\n",
    "save_array(save_path + 'train_sequence_2', train_sequence_1)\n",
    "save_array(save_path + 'train_labels',  train_labels)\n",
    "\n",
    "save_array(save_path + 'test_sequence_1',  test_sequence_1)\n",
    "save_array(save_path + 'test_sequence_2',  test_sequence_2)\n",
    "\n",
    "save_array(save_path + 'word_index',  tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# load back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sequence_1 = load_array(save_path + 'train_sequence_1')\n",
    "train_sequence_2 = load_array(save_path + 'train_sequence_2')\n",
    "\n",
    "test_sequence_1 = load_array(save_path + 'test_sequence_1')\n",
    "test_sequence_2 = load_array(save_path + 'test_sequence_2')\n",
    "\n",
    "train_labels = load_array(save_path + 'train_labels')\n",
    "\n",
    "word_index = load_array(save_path + 'word_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(nb_samples) < 0.8\n",
    "msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 30), (404290, 30))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_sequence_1.shape, train_sequence_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 60)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.hstack((train_sequence_1, train_sequence_2))\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290,), 0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = np.array(train_labels)\n",
    "y_all.shape, y_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323433, 60), (323433,), (80857, 60), (80857,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_all[msk]\n",
    "X_valid = X_all[~msk]\n",
    "y_train = y_all[msk]\n",
    "y_valid = y_all[~msk]\n",
    "(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, 60, 50)        1000000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 3000)          0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 200)           600200      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             201         dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,600,401\n",
      "Trainable params: 1,600,401\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        Embedding(20000, 50, input_length=60),\n",
    "        Flatten(),\n",
    "        #Dropout(0.5),\n",
    "        #BatchNormalization(),\n",
    "        Dense(200, activation='sigmoid'),\n",
    "        #Dropout(0.5),\n",
    "        #BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tokenizer.nb_words\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n",
    "    #ModelCheckpoint(model_path + 'word2vec_dropout.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323433 samples, validate on 80857 samples\n",
      "Epoch 1/20\n",
      "217s - loss: 0.5313 - val_loss: 0.5099\n",
      "Epoch 2/20\n",
      "300s - loss: 0.4617 - val_loss: 0.5154\n",
      "Epoch 3/20\n",
      "284s - loss: 0.4227 - val_loss: 0.5257\n",
      "Epoch 4/20\n",
      "283s - loss: 0.3968 - val_loss: 0.5564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43f372b810>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "          batch_size=64, nb_epoch=20, verbose=2,\n",
    "          callbacks=callbacks\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82588512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = model.predict_classes(X_train, verbose=2)\n",
    "sum(pred_train == y_train.reshape(len(y_train), 1)) * 1.0 / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7577278])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid = model.predict_classes(X_valid, verbose=2)\n",
    "sum(pred_valid == y_valid.reshape(len(y_valid), 1)) * 1.0 / len(y_valid)\n",
    "#pred_valid.shape, y_valid.shape, len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.17802152], dtype=float32), 0),\n",
       " (array([ 0.38128787], dtype=float32), 0),\n",
       " (array([ 0.42360657], dtype=float32), 1),\n",
       " (array([ 0.24209851], dtype=float32), 0),\n",
       " (array([ 0.60948128], dtype=float32), 0),\n",
       " (array([ 0.71274632], dtype=float32), 0),\n",
       " (array([ 0.43072778], dtype=float32), 1),\n",
       " (array([ 0.09452189], dtype=float32), 0),\n",
       " (array([ 0.73663753], dtype=float32), 0),\n",
       " (array([ 0.97041601], dtype=float32), 1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(model.predict_proba(X_valid, verbose=2)[0:10], y_valid[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 60)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.hstack((test_sequence_1, test_sequence_2))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict_proba(X_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 650316.0625], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_submission.shape\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.419504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.425452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.266448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.382258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.100530\n",
       "1        1      0.419504\n",
       "2        2      0.425452\n",
       "3        3      0.266448\n",
       "4        4      0.382258"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_test.shape\n",
    "df_submission['is_duplicate'] = pred_test\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/h1_2epochs_prob_20170504.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
