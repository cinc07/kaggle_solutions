{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import Stemmer\n",
    "\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "import gc\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "#plt.rcParams['figure.figsize'] = 16, 12\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/quora-question-pairs/save_data_tf_idf/'\n",
    "model_path = '/cinc/data/quora-question-pairs/save_data_tf_idf/model/'\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def cosine_sim(text1, text2):\n",
    "#    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "#    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem version cosine_sim\n",
    "english_stemmer = Stemmer.Stemmer('en')\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: english_stemmer.stemWords(analyzer(doc))\n",
    "\n",
    "stem_vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english', analyzer='word', ngram_range=(1,1))\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = stem_vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.709297266606\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print cosine_sim('a little bird', 'a little bird')\n",
    "print cosine_sim('a little bird', 'a little bird chirps')\n",
    "print cosine_sim('a little bird', 'a big dog barks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "#    if stem_words:\n",
    "#        text = text.split()\n",
    "#        stemmer = SnowballStemmer('english')\n",
    "#        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "#        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read train text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv(path + 'train/train-sample.csv')\n",
    "train_data = pd.read_csv(path + 'train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = train_data.shape[0]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_real_feature(df, fname):\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((3, 2), (0, 0), colspan=2)\n",
    "    ax2 = plt.subplot2grid((3, 2), (1, 0), colspan=2)\n",
    "    ax3 = plt.subplot2grid((3, 2), (2, 0))\n",
    "    ax4 = plt.subplot2grid((3, 2), (2, 1))\n",
    "    ax1.set_title('Distribution of %s' % fname, fontsize=20)\n",
    "    sns.distplot(df.loc[ix_train][fname], \n",
    "                 bins=50, \n",
    "                 ax=ax1)    \n",
    "    sns.distplot(df.loc[ix_is_dup][fname], \n",
    "                 bins=50, \n",
    "                 ax=ax2,\n",
    "                 label='is dup')    \n",
    "    sns.distplot(df.loc[ix_not_dup][fname], \n",
    "                 bins=50, \n",
    "                 ax=ax2,\n",
    "                 label='not dup')\n",
    "    ax2.legend(loc='upper right', prop={'size': 18})\n",
    "    sns.boxplot(y=fname, \n",
    "                x='is_duplicate', \n",
    "                data=df.loc[ix_train], \n",
    "                ax=ax3)\n",
    "    sns.violinplot(y=fname, \n",
    "                   x='is_duplicate', \n",
    "                   data=df.loc[ix_train], \n",
    "                   ax=ax4)\n",
    "    plt.show()\n",
    "    \n",
    "#plot_real_feature(train_data, 'log_diff_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ratio_len(text1, text2):\n",
    "    r = 1.0 * (len(text1)+1) / (len(text2)+1)\n",
    "    if r>1:\n",
    "        r = 1/r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(df_data):\n",
    "    print 'remove stop words (1)...'\n",
    "    df_data['question1'] = df_data['question1'].apply(lambda x: text_to_wordlist(str(x)))\n",
    "    print 'remove stop words (2)...'\n",
    "    df_data['question2'] = df_data['question2'].apply(lambda x: text_to_wordlist(str(x)))\n",
    "\n",
    "    print 'calculate length features...'\n",
    "    df_data['diff_len'] = df_data.apply(lambda row: abs(len(row['question1']) - len(row['question2'])), axis=1)\n",
    "    df_data['ratio_len'] = df_data.apply(lambda row: ratio_len(row['question1'], row['question2']), axis=1)\n",
    "    df_data['log_diff_len'] = np.log(df_data['diff_len']+0.01)\n",
    "    return df_data\n",
    "\n",
    "def process_cosine_sims(df_data):\n",
    "    cosine_sims = [None]*df_data.shape[0]\n",
    "    for i in tqdm(range(df_data.shape[0])):\n",
    "        try:\n",
    "            cosine_sims[i] = cosine_sim(df_data['question1'][i], df_data['question2'][i])\n",
    "        except ValueError:\n",
    "            cosine_sims[i] = 0\n",
    "    df_data['cos_sim'] = cosine_sims\n",
    "\n",
    "    return df_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_calculate_ngram_score(m_q1, m_q2, ix_ngrams, name):\n",
    "    print ('calculating ngram score for ' + name)\n",
    "    v_num = (m_q1[:, ix_ngrams] > 0).minimum((m_q2[:, ix_ngrams] > 0)).sum(axis=1)\n",
    "    v_den = (m_q1[:, ix_ngrams] > 0).maximum((m_q2[:, ix_ngrams] > 0)).sum(axis=1)\n",
    "    v_score_ngram_jaccard = np.array(v_num.flatten()).astype(np.float32)[0, :] / (np.array(v_den.flatten())[0, :] + 0.001)\n",
    "\n",
    "    v_num = m_q1[:, ix_ngrams].minimum(m_q2[:, ix_ngrams]).sum(axis=1)\n",
    "    v_den = m_q1[:, ix_ngrams].sum(axis=1) + m_q2[:, ix_ngrams].sum(axis=1)\n",
    "    v_score_ngram_jaccard_all = np.array(v_num.flatten()).astype(np.float32)[0, :] / (np.array(v_den.flatten())[0, :] + 0.001)\n",
    "    \n",
    "    v_num = m_q1[:, ix_ngrams].minimum(m_q2[:, ix_ngrams]).sum(axis=1)\n",
    "    v_den = m_q1[:, ix_ngrams].maximum(m_q2[:, ix_ngrams]).sum(axis=1)\n",
    "    v_score_ngram_jaccard_max = np.array(v_num.flatten()).astype(np.float32)[0, :] / (np.array(v_den.flatten())[0, :] + 0.001)\n",
    "    \n",
    "    return (v_score_ngram_jaccard, v_score_ngram_jaccard_all, v_score_ngram_jaccard_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_calculate_ngram(df_data):\n",
    "    print ('calculating ngrams ...')\n",
    "    cv_char = CountVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "    cv_char.fit_transform(df_data['question1'][0:10000].tolist() + df_data['question2'][0:10000].tolist()) \\\n",
    "    .sum(axis=0)[0, :].shape\n",
    "    \n",
    "    ch_freq = np.array(cv_char.fit_transform(df_data['question1'].values.astype('U').tolist()\n",
    "                                         + df_data['question2'].values.astype('U').tolist()).sum(axis=0))[0, :]\n",
    "    \n",
    "    unigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 1])\n",
    "    ix_unigrams = np.sort(unigrams.values())\n",
    "    print 'Unigrams:', len(unigrams)\n",
    "\n",
    "    bigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 2])\n",
    "    ix_bigrams = np.sort(bigrams.values())\n",
    "    print 'Bigrams: ', len(bigrams)\n",
    "\n",
    "    trigrams = dict([(k, v) for (k, v) in cv_char.vocabulary_.items() if len(k) == 3])\n",
    "    ix_trigrams = np.sort(trigrams.values())\n",
    "    print 'Trigrams:', len(trigrams)\n",
    "    \n",
    "    print ('tranform q1 and q2...')\n",
    "    m_q1 = cv_char.transform(df_data['question1'].values.astype('U'))\n",
    "    m_q2 = cv_char.transform(df_data['question2'].values.astype('U'))\n",
    "    \n",
    "    print ('calculating  q1 and q2...')\n",
    "    (jac, jac_all, jac_max) =  process_calculate_ngram_score(m_q1, m_q2, ix_unigrams, 'unigram')\n",
    "    print (jac[0:5], jac_all[0:5], jac_max[0:5])\n",
    "    df_data['unigram_jaccard'] = jac\n",
    "    df_data['unigram_jaccard_all'] = jac_all\n",
    "    df_data['unigram_jaccard_max'] = jac_max\n",
    "    \n",
    "    (jac, jac_all, jac_max) =  process_calculate_ngram_score(m_q1, m_q2, ix_bigrams, 'bigram')\n",
    "    print (jac[0:5], jac_all[0:5], jac_max[0:5])\n",
    "    df_data['bigram_jaccard'] = jac\n",
    "    df_data['bigram_jaccard_all'] = jac_all\n",
    "    df_data['bigram_jaccard_max'] = jac_max\n",
    "    \n",
    "    (jac, jac_all, jac_max) =  process_calculate_ngram_score(m_q1, m_q2, ix_trigrams, 'trigram')\n",
    "    print (jac[0:5], jac_all[0:5], jac_max[0:5])\n",
    "    df_data['trigram_jaccard'] = jac\n",
    "    df_data['trigram_jaccard_all'] = jac_all\n",
    "    df_data['trigram_jaccard_max'] = jac_max\n",
    "    \n",
    "    #return (ix_unigrams, ix_bigrams, ix_trigrams)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data['question1'] = train_data['question1'].apply(lambda x: text_to_wordlist(str(x)))\n",
    "#train_data['question2'] = train_data['question2'].apply(lambda x: text_to_wordlist(str(x)))\n",
    "#train_data.head()\n",
    "\n",
    "#cosine_sims = [None]*train_data.shape[0]\n",
    "#for i in range(train_data.shape[0]):\n",
    "#    try:\n",
    "#        cosine_sims[i] = cosine_sim(train_data['question1'][i], train_data['question2'][i])\n",
    "#    except ValueError:\n",
    "#        cosine_sims[i] = 0\n",
    "\n",
    "#train_data['cos_sim'] = cosine_sims\n",
    "#train_data['diff_len'] = train_data.apply(lambda row: abs(len(row['question1']) - len(row['question2'])), axis=1)\n",
    "#train_data['ratio_len'] = train_data.apply(lambda row: ratio_len(row['question1'], row['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove stop words (1)...\n",
      "remove stop words (2)...\n",
      "calculate length features...\n"
     ]
    }
   ],
   "source": [
    "train_data = process_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [19:46<00:00, 340.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = process_cosine_sims(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_calculate_ngram(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data['question1'] = train_data['question1'].fillna('')\n",
    "#train_data['question2'] = train_data['question2'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv(save_path + 'train_data.csv')\n",
    "save_array(save_path + 'train_data_cos_sim', list(train_data['cos_sim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back\n",
    "cos_sims = load_array(save_path + 'train_data_cos_sim')\n",
    "train_data['cos_sim'] = cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "#save_array(save_path + 'train_data', train_data)\n",
    "train_data.to_csv(save_path + 'train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>ratio_len</th>\n",
       "      <th>cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.895532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor koh - i - noor d...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.474331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.380873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math 23 ^ 24 math is d...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.206084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor koh - i - noor d...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely how can i solve it    \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  diff_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0         9   \n",
       "1  what would happen if the indian government sto...             0        37   \n",
       "2  how can internet speed be increased by hacking...             0        14   \n",
       "3  find the remainder when math 23 ^ 24 math is d...             0        13   \n",
       "4            which fish would survive in salt water              0        35   \n",
       "\n",
       "   ratio_len   cos_sim  \n",
       "0   0.865672  0.895532  \n",
       "1   0.593407  0.474331  \n",
       "2   0.810811  0.380873  \n",
       "3   0.793651  0.000000  \n",
       "4   0.533333  0.206084  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load back\n",
    "train_data = pd.read_csv(save_path + 'train_data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'diff_len', u'ratio_len', u'cos_sim'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(path + 'test/test.csv')\n",
    "#test_data.index = test_data.index-1\n",
    "#print test_data.shape\n",
    "#test_data = test_data[0:1000]\n",
    "\n",
    "print test_data.shape\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove stop words (1)...\n",
      "remove stop words (2)...\n",
      "calculate length features...\n"
     ]
    }
   ],
   "source": [
    "test_data = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2345796/2345796 [1:23:06<00:00, 470.46it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = process_cosine_sims(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating ngrams ...\n",
      "Unigrams: 45\n",
      "Bigrams:  1451\n",
      "Trigrams: 20406\n",
      "tranform q1 and q2...\n",
      "calculating  q1 and q2...\n",
      "calculating ngram score for unigram\n",
      "(array([ 0.80948526,  0.77269215,  0.83328704,  0.61107716,  0.81244922]), array([ 0.39837074,  0.35848718,  0.32183538,  0.3333254 ,  0.39654489]), array([ 0.66215321,  0.55881531,  0.47456823,  0.49998214,  0.65712408]))\n",
      "calculating ngram score for bigram\n",
      "(array([ 0.30666258,  0.46550922,  0.4599908 ,  0.21874316,  0.44735665]), array([ 0.21487426,  0.27884347,  0.27058505,  0.17499563,  0.30356601]), array([ 0.27368133,  0.38666151,  0.37096176,  0.21211478,  0.43588626]))\n",
      "calculating ngram score for trigram\n",
      "(array([ 0.14285569,  0.35210772,  0.34482164,  0.08571184,  0.34999125]), array([ 0.11764607,  0.24509564,  0.24096095,  0.07894529,  0.25925446]), array([ 0.13333206,  0.32467111,  0.31745528,  0.08571184,  0.34999125]))\n"
     ]
    }
   ],
   "source": [
    "process_calculate_ngram(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save_array(save_path + 'test_data_cos_sim', list(test_data['cos_sim']))\n",
    "cos_sims = load_array(save_path + 'test_data_cos_sim')\n",
    "test_data['cos_sim'] = cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "test_data.to_csv(save_path + 'test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back\n",
    "test_data = pd.read_csv(save_path + 'test_data.csv')\n",
    "print test_data.shape\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>ratio_len</th>\n",
       "      <th>log_diff_len</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>unigram_jaccard</th>\n",
       "      <th>unigram_jaccard_all</th>\n",
       "      <th>unigram_jaccard_max</th>\n",
       "      <th>bigram_jaccard</th>\n",
       "      <th>bigram_jaccard_all</th>\n",
       "      <th>bigram_jaccard_max</th>\n",
       "      <th>trigram_jaccard</th>\n",
       "      <th>trigram_jaccard_all</th>\n",
       "      <th>trigram_jaccard_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>how does the surface pro himself 4 compare wit...</td>\n",
       "      <td>why did microsoft choose core m3 and not core ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>2.398804</td>\n",
       "      <td>0.194593</td>\n",
       "      <td>0.809485</td>\n",
       "      <td>0.398371</td>\n",
       "      <td>0.662153</td>\n",
       "      <td>0.306663</td>\n",
       "      <td>0.214874</td>\n",
       "      <td>0.273681</td>\n",
       "      <td>0.142856</td>\n",
       "      <td>0.117646</td>\n",
       "      <td>0.133332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>should i have a hair transplant at age 24 how ...</td>\n",
       "      <td>how much cost does hair transplant require</td>\n",
       "      <td>22</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>3.091497</td>\n",
       "      <td>0.431613</td>\n",
       "      <td>0.772692</td>\n",
       "      <td>0.358487</td>\n",
       "      <td>0.558815</td>\n",
       "      <td>0.465509</td>\n",
       "      <td>0.278843</td>\n",
       "      <td>0.386662</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>0.245096</td>\n",
       "      <td>0.324671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>what but is the best way to send money from ch...</td>\n",
       "      <td>what you send money to china</td>\n",
       "      <td>31</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>3.434310</td>\n",
       "      <td>0.656973</td>\n",
       "      <td>0.833287</td>\n",
       "      <td>0.321835</td>\n",
       "      <td>0.474568</td>\n",
       "      <td>0.459991</td>\n",
       "      <td>0.270585</td>\n",
       "      <td>0.370962</td>\n",
       "      <td>0.344822</td>\n",
       "      <td>0.240961</td>\n",
       "      <td>0.317455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>which food not emulsifiers</td>\n",
       "      <td>what foods fibre</td>\n",
       "      <td>10</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>2.303585</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>0.611077</td>\n",
       "      <td>0.333325</td>\n",
       "      <td>0.499982</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>0.174996</td>\n",
       "      <td>0.212115</td>\n",
       "      <td>0.085712</td>\n",
       "      <td>0.078945</td>\n",
       "      <td>0.085712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>how aberystwyth start reading</td>\n",
       "      <td>how their can i start reading</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.605170</td>\n",
       "      <td>0.709297</td>\n",
       "      <td>0.812449</td>\n",
       "      <td>0.396545</td>\n",
       "      <td>0.657124</td>\n",
       "      <td>0.447357</td>\n",
       "      <td>0.303566</td>\n",
       "      <td>0.435886</td>\n",
       "      <td>0.349991</td>\n",
       "      <td>0.259254</td>\n",
       "      <td>0.349991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  how does the surface pro himself 4 compare wit...   \n",
       "1        1  should i have a hair transplant at age 24 how ...   \n",
       "2        2  what but is the best way to send money from ch...   \n",
       "3        3                         which food not emulsifiers   \n",
       "4        4                      how aberystwyth start reading   \n",
       "\n",
       "                                           question2  diff_len  ratio_len  \\\n",
       "0  why did microsoft choose core m3 and not core ...        11   0.838235   \n",
       "1         how much cost does hair transplant require        22   0.661538   \n",
       "2                       what you send money to china        31   0.483333   \n",
       "3                                   what foods fibre        10   0.629630   \n",
       "4                      how their can i start reading         0   1.000000   \n",
       "\n",
       "   log_diff_len   cos_sim  unigram_jaccard  unigram_jaccard_all  \\\n",
       "0      2.398804  0.194593         0.809485             0.398371   \n",
       "1      3.091497  0.431613         0.772692             0.358487   \n",
       "2      3.434310  0.656973         0.833287             0.321835   \n",
       "3      2.303585  0.336097         0.611077             0.333325   \n",
       "4     -4.605170  0.709297         0.812449             0.396545   \n",
       "\n",
       "   unigram_jaccard_max  bigram_jaccard  bigram_jaccard_all  \\\n",
       "0             0.662153        0.306663            0.214874   \n",
       "1             0.558815        0.465509            0.278843   \n",
       "2             0.474568        0.459991            0.270585   \n",
       "3             0.499982        0.218743            0.174996   \n",
       "4             0.657124        0.447357            0.303566   \n",
       "\n",
       "   bigram_jaccard_max  trigram_jaccard  trigram_jaccard_all  \\\n",
       "0            0.273681         0.142856             0.117646   \n",
       "1            0.386662         0.352108             0.245096   \n",
       "2            0.370962         0.344822             0.240961   \n",
       "3            0.212115         0.085712             0.078945   \n",
       "4            0.435886         0.349991             0.259254   \n",
       "\n",
       "   trigram_jaccard_max  \n",
       "0             0.133332  \n",
       "1             0.324671  \n",
       "2             0.317455  \n",
       "3             0.085712  \n",
       "4             0.349991  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = train_data\n",
    "df_train['test_id'] = -1\n",
    "\n",
    "df_test = test_data\n",
    "df_test['id'] = -1\n",
    "df_test['qid1'] = -1\n",
    "df_test['qid2'] = -1\n",
    "df_test['is_duplicate'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2750086, 21)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "df['question1'] = df['question1'].fillna('')\n",
    "df['question2'] = df['question2'].fillna('')\n",
    "df['uid'] = np.arange(df.shape[0])\n",
    "df = df.set_index(['uid'])\n",
    "print df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'bigram_jaccard', u'bigram_jaccard_all', u'bigram_jaccard_max',\n",
       "       u'cos_sim', u'diff_len', u'id', u'is_duplicate', u'log_diff_len',\n",
       "       u'qid1', u'qid2', u'question1', u'question2', u'ratio_len', u'test_id',\n",
       "       u'trigram_jaccard', u'trigram_jaccard_all', u'trigram_jaccard_max',\n",
       "       u'unigram_jaccard', u'unigram_jaccard_all', u'unigram_jaccard_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>log_diff_len</th>\n",
       "      <th>ratio_len</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>diff_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>2.198335</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.895532</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor koh - i - noor d...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>3.611188</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.474331</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.380873</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math 23 ^ 24 math is d...</td>\n",
       "      <td>2.565718</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>3.555634</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.206084</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  test_id  is_duplicate  qid1  qid2  \\\n",
       "uid                                          \n",
       "0     0       -1             0     1     2   \n",
       "1     1       -1             0     3     4   \n",
       "2     2       -1             0     5     6   \n",
       "3     3       -1             0     7     8   \n",
       "4     4       -1             0     9    10   \n",
       "\n",
       "                                             question1  \\\n",
       "uid                                                      \n",
       "0    what is the step by step guide to invest in sh...   \n",
       "1    what is the story of kohinoor koh - i - noor d...   \n",
       "2    how can i increase the speed of my internet co...   \n",
       "3    why am i mentally very lonely how can i solve it    \n",
       "4    which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                             question2  log_diff_len  \\\n",
       "uid                                                                    \n",
       "0    what is the step by step guide to invest in sh...      2.198335   \n",
       "1    what would happen if the indian government sto...      3.611188   \n",
       "2    how can internet speed be increased by hacking...      2.639771   \n",
       "3    find the remainder when math 23 ^ 24 math is d...      2.565718   \n",
       "4              which fish would survive in salt water       3.555634   \n",
       "\n",
       "     ratio_len   cos_sim  diff_len  \n",
       "uid                                 \n",
       "0     0.865672  0.895532         9  \n",
       "1     0.593407  0.474331        37  \n",
       "2     0.810811  0.380873        14  \n",
       "3     0.793651  0.000000        13  \n",
       "4     0.533333  0.206084        35  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [u'id', u'test_id', u'is_duplicate', \n",
    "              u'qid1', u'qid2', u'question1', u'question2', \n",
    "              u'log_diff_len', u'ratio_len', u'cos_sim', u'diff_len']\n",
    "df = df[columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'log_diff_len', u'ratio_len', u'cos_sim', u'diff_len'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ix_train = np.where(df['id'] >= 0)[0]\n",
    "ix_test = np.where(df['id'] == -1)[0]\n",
    "ix_is_dup = np.where(df['is_duplicate'] == 1)[0]\n",
    "ix_not_dup = np.where(df['is_duplicate'] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_real_feature(df, 'log_diff_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_real_feature(train_data, 'ratio_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot_real_feature(train_data, 'cos_sim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# edge feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.add_nodes_from(df.question1)\n",
    "g.add_nodes_from(df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = list(df[['question1', 'question2']].to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection_count(row):\n",
    "    try:\n",
    "        result = len(set(g.neighbors(row.question1)).intersection(set(g.neighbors(row.question2))))\n",
    "    except nx.NetworkXError:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data[0:1]\n",
    "train_data['intersection_count'] = train_data.apply(lambda row: get_intersection_count(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data['intersection_count']\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['intersection_count'] = test_data.apply(lambda row: get_intersection_count(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for later\n",
    "train_data.to_csv(save_path + 'train_data.csv', index=False)\n",
    "test_data.to_csv(save_path + 'test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating qratio...\n",
      "calculating wratio...\n",
      "calculating partial ratio...\n"
     ]
    }
   ],
   "source": [
    "print \"calculating qratio...\"\n",
    "train_data['fuzz_qratio'] = train_data.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "print \"calculating wratio...\"\n",
    "train_data['fuzz_wratio'] = train_data.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "print \"calculating partial ratio...\"\n",
    "train_data['fuzz_partial_ratio'] = train_data.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating partial token set ratio...\n",
      "calculating partial token sort ratio...\n",
      "calculating token set ratio...\n",
      "calculating token sort ratio...\n"
     ]
    }
   ],
   "source": [
    "print \"calculating partial token set ratio...\"\n",
    "train_data['fuzz_partial_token_set_ratio'] = train_data.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "print \"calculating partial token sort ratio...\"\n",
    "train_data['fuzz_partial_token_sort_ratio'] = train_data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "print \"calculating token set ratio...\"\n",
    "train_data['fuzz_token_set_ratio'] = train_data.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "print \"calculating token sort ratio...\"\n",
    "train_data['fuzz_token_sort_ratio'] = train_data.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_fuzz(df_data):\n",
    "    print \"calculating qratio...\"\n",
    "    df_data['fuzz_qratio'] = df_data.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating wratio...\"\n",
    "    df_data['fuzz_wratio'] = df_data.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating partial ratio...\"\n",
    "    df_data['fuzz_partial_ratio'] = df_data.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating partial token set ratio...\"\n",
    "    df_data['fuzz_partial_token_set_ratio'] = df_data.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating partial token sort ratio...\"\n",
    "    df_data['fuzz_partial_token_sort_ratio'] = df_data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating token set ratio...\"\n",
    "    df_data['fuzz_token_set_ratio'] = df_data.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    print \"calculating token sort ratio...\"\n",
    "    df_data['fuzz_token_sort_ratio'] = df_data.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating wratio...\n",
      "calculating partial ratio...\n",
      "calculating partial token set ratio...\n",
      "calculating partial token sort ratio...\n",
      "calculating token set ratio...\n",
      "calculating token sort ratio...\n"
     ]
    }
   ],
   "source": [
    "process_fuzz(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating qratio...\n",
      "calculating wratio...\n",
      "calculating partial ratio...\n",
      "calculating partial token set ratio...\n",
      "calculating partial token sort ratio...\n",
      "calculating token set ratio...\n",
      "calculating token sort ratio...\n"
     ]
    }
   ],
   "source": [
    "process_fuzz(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(save_path + 'train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv(save_path + 'test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  100000\n",
      "processing  200000\n",
      "processing  300000\n",
      "processing  400000\n",
      "processing  500000\n",
      "processing  600000\n",
      "processing  700000\n",
      "processing  800000\n",
      "processing  900000\n",
      "processing  1000000\n",
      "processing  1100000\n",
      "processing  1200000\n",
      "processing  1300000\n",
      "processing  1400000\n",
      "processing  1500000\n",
      "processing  1600000\n",
      "processing  1700000\n",
      "processing  1800000\n",
      "processing  1900000\n",
      "processing  2000000\n",
      "processing  2100000\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "glove_file = '/cinc/data/glove/glove.840B.300d.txt'\n",
    "f = open(glove_file)\n",
    "\n",
    "count = 0\n",
    "for line in f:\n",
    "    count = count+1\n",
    "    if (count % 100000) == 0:\n",
    "        print 'processing ', count\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_processing(s):\n",
    "    words = word_tokenize(s)\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('what is the step by step guide to invest in share market in india ',\n",
       " ['step', 'step', 'guide', 'invest', 'share', 'market', 'india'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['question1'][0], pre_processing(train_data['question1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    embedding_matrix = []\n",
    "    for w in s:\n",
    "        embedding_vector = embeddings_index.get(w)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix.append(embedding_vector)\n",
    "        #else:\n",
    "            #print w\n",
    "    # normalize\n",
    "    embedding_norm = np.array(embedding_matrix).sum(axis=0)\n",
    "    denom = np.sqrt((embedding_norm ** 2).sum())\n",
    "    return embedding_norm / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031762361526489258"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = sent2vec(pre_processing(train_data['question1'][0]))\n",
    "v2 = sent2vec(pre_processing(train_data['question2'][0]))\n",
    "cosine(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-8a48cc7e88d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#train_data_10 = train_data.iloc[0:10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprocess_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#train_data_10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-8a48cc7e88d8>\u001b[0m in \u001b[0;36mprocess_distance\u001b[0;34m(df_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mq1_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mq1_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_distance(df_data):\n",
    "    q1_vec = np.zeros((df_data.shape[0], 300))\n",
    "    for i in tqdm(range(df_data.shape[0])):\n",
    "        q1_vec[i,:] = sent2vec(df_data['question1'][i])\n",
    "        \n",
    "    q2_vec = np.zeros((df_data.shape[0], 300))\n",
    "    for i in tqdm(range(df_data.shape[0])):\n",
    "        q2_vec[i,:] = sent2vec(df_data['question2'][i])\n",
    "\n",
    "    df_data['cosine_distance'] = [cosine(x, y) for (x, y) in zip(q1_vec, q2_vec)]\n",
    "    df_data['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(q1_vec, q2_vec)]\n",
    "\n",
    "#train_data_10 = train_data.iloc[0:10]\n",
    "process_distance(train_data)\n",
    "#train_data_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back\n",
    "train_data = pd.read_csv(save_path + 'train_data.csv')\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load back\n",
    "test_data = pd.read_csv(save_path + 'test_data.csv')\n",
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_data['intersection_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data.groupby('diff_len')['id'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(train_data['log_diff_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(train_data['ratio_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'diff_len', u'ratio_len', u'cos_sim', u'fuzz_qratio', u'fuzz_wratio',\n",
       "       u'fuzz_partial_ratio', u'fuzz_partial_token_set_ratio',\n",
       "       u'fuzz_partial_token_sort_ratio', u'fuzz_token_set_ratio',\n",
       "       u'fuzz_token_sort_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = train_data.columns[6:]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = train_data[['cos_sim', 'diff_len', 'ratio_len']]\n",
    "X_train = train_data[predictors]\n",
    "y_train = train_data['is_duplicate']\n",
    "model=LogisticRegression(penalty='l2').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66420638650473673"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.11177693e-01,   2.21360878e-01,   9.45436483e-02,\n",
       "         1.54366628e-04,   4.92499783e-02,   2.99633996e-01,\n",
       "         1.54035376e-04,   1.51472548e-01,   8.62901512e-01,\n",
       "         9.26676989e-02])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10,1]  #, np.argmax(y_pred[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = lambda: SGDClassifier(\n",
    "    loss='log', \n",
    "    penalty='elasticnet', \n",
    "    fit_intercept=True, \n",
    "    n_iter=100, \n",
    "    shuffle=True, \n",
    "    n_jobs=-1,\n",
    "    class_weight=None)\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('en', classifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'en__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.02, 0.1, 0.5, 0.9, 1],\n",
    "    'en__l1_ratio': [0, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.75, 0.9, 1]\n",
    "}\n",
    "\n",
    "folder = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    model, \n",
    "    parameters, \n",
    "    cv=folder, \n",
    "    n_jobs=-1, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 444 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed: 31.7min finished\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845022137575\n",
      "{'en__l1_ratio': 0.3, 'en__alpha': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print model.best_score_\n",
    "print model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(model_path + 'model_fuzz.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cinc/Application/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(y_train.shape[0]) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[msk], y_train[msk], feature_names=predictors)\n",
    "dvalid = xgb.DMatrix(X_train[~msk], y_train[~msk], feature_names=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 1.0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-rmse:0.485236\n",
      "Will train until val-rmse hasn't improved in 20 rounds.\n",
      "[20]\tval-rmse:0.368616\n",
      "[40]\tval-rmse:0.327322\n",
      "[60]\tval-rmse:0.314667\n",
      "[80]\tval-rmse:0.31111\n"
     ]
    }
   ],
   "source": [
    "partial_model = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=[(dvalid, 'val')],\n",
    "                       early_stopping_rounds=20, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 16))\n",
    "#xgb.plot_importance(partial_model, height=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 22)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data[predictors]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'diff_len', u'ratio_len', u'cos_sim', u'log_diff_len', u'test_id',\n",
       "       u'unigram_jaccard', u'unigram_jaccard_all', u'unigram_jaccard_max',\n",
       "       u'bigram_jaccard', u'bigram_jaccard_all', u'bigram_jaccard_max',\n",
       "       u'trigram_jaccard', u'trigram_jaccard_all', u'trigram_jaccard_max',\n",
       "       u'intersection_count', u'fuzz_qratio', u'fuzz_wratio',\n",
       "       u'fuzz_partial_ratio', u'fuzz_partial_token_set_ratio',\n",
       "       u'fuzz_partial_token_sort_ratio', u'fuzz_token_set_ratio',\n",
       "       u'fuzz_token_sort_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2.80286874e-02,   1.81131941e-01,   3.75304679e-01,\n",
       "         4.50084808e-04,   2.16294791e-01,   3.95692383e-02,\n",
       "         1.00000000e+00,   4.55689053e-02,   4.11544304e-01,\n",
       "         4.12248822e-02])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_test_pred.shape\n",
    "y_test_pred[0:10,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_submission.shape\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.2163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0        0.0280\n",
       "1        1        0.1811\n",
       "2        2        0.3753\n",
       "3        3        0.0005\n",
       "4        4        0.2163"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_submission['is_duplicate'] = test_data['cos_sim']\n",
    "df_submission['is_duplicate'] = y_test_pred[:,1]\n",
    "df_submission['is_duplicate'] = df_submission['is_duplicate'].apply(lambda x: float(\"{:.4f}\".format(x)))\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/quora_feature_engineering_fuzz_20170603.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
