{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is enabled with initial size: 75.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, Flatten, Embedding, LSTM, merge, TimeDistributed, concatenate, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/cinc/data/quora-question-pairs/'\n",
    "save_path = '/cinc/data/quora-question-pairs/save_data/'\n",
    "model_path = '/cinc/data/quora-question-pairs/model/'\n",
    "\n",
    "word2vec_file = '/cinc/data/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "glove_file = '/cinc/data/glove/glove.840B.300d.txt'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sequence_1 = load_array(save_path + 'train_sequence_1')\n",
    "train_sequence_2 = load_array(save_path + 'train_sequence_2')\n",
    "\n",
    "test_sequence_1 = load_array(save_path + 'test_sequence_1')\n",
    "test_sequence_2 = load_array(save_path + 'test_sequence_2')\n",
    "\n",
    "train_labels = load_array(save_path + 'train_labels')\n",
    "\n",
    "word_index = load_array(save_path + 'word_index')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120501"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_words = len(word_index) + 1\n",
    "nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 30), (404290, 30), (2345796, 30), (2345796, 30))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence_1.shape, train_sequence_2.shape, test_sequence_1.shape, test_sequence_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#embedding_matrix = load_array(save_path + 'embedding_matrix')\n",
    "#embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  100000\n",
      "processing  200000\n",
      "processing  300000\n",
      "processing  400000\n",
      "processing  500000\n",
      "processing  600000\n",
      "processing  700000\n",
      "processing  800000\n",
      "processing  900000\n",
      "processing  1000000\n",
      "processing  1100000\n",
      "processing  1200000\n",
      "processing  1300000\n",
      "processing  1400000\n",
      "processing  1500000\n",
      "processing  1600000\n",
      "processing  1700000\n",
      "processing  1800000\n",
      "processing  1900000\n",
      "processing  2000000\n",
      "processing  2100000\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(glove_file)\n",
    "count = 0\n",
    "for line in f:\n",
    "    count = count+1\n",
    "    if (count % 100000) == 0:\n",
    "        print 'processing ', count\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(save_path + 'embedding_matrix', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120501, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = load_array(save_path + 'embedding_matrix')\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# leak input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(save_path + '../save_data_tf_idf/train_data.csv')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(save_path + '../save_data_tf_idf/test_data.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([u'diff_len', u'ratio_len', u'cos_sim', u'log_diff_len', u'test_id',\n",
       "        u'unigram_jaccard', u'unigram_jaccard_all', u'unigram_jaccard_max',\n",
       "        u'bigram_jaccard', u'bigram_jaccard_all', u'bigram_jaccard_max',\n",
       "        u'trigram_jaccard', u'trigram_jaccard_all', u'trigram_jaccard_max',\n",
       "        u'intersection_count', u'fuzz_qratio', u'fuzz_wratio',\n",
       "        u'fuzz_partial_ratio', u'fuzz_partial_token_set_ratio',\n",
       "        u'fuzz_partial_token_sort_ratio', u'fuzz_token_set_ratio',\n",
       "        u'fuzz_token_sort_ratio'],\n",
       "       dtype='object'), 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = train_data.columns[6:]\n",
    "predictors, len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_len</th>\n",
       "      <th>ratio_len</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>log_diff_len</th>\n",
       "      <th>test_id</th>\n",
       "      <th>unigram_jaccard</th>\n",
       "      <th>unigram_jaccard_all</th>\n",
       "      <th>unigram_jaccard_max</th>\n",
       "      <th>bigram_jaccard</th>\n",
       "      <th>bigram_jaccard_all</th>\n",
       "      <th>...</th>\n",
       "      <th>trigram_jaccard_all</th>\n",
       "      <th>trigram_jaccard_max</th>\n",
       "      <th>intersection_count</th>\n",
       "      <th>fuzz_qratio</th>\n",
       "      <th>fuzz_wratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.895532</td>\n",
       "      <td>2.198335</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.463411</td>\n",
       "      <td>0.863623</td>\n",
       "      <td>0.906956</td>\n",
       "      <td>0.462806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462181</td>\n",
       "      <td>0.859362</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.474331</td>\n",
       "      <td>3.611188</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.666639</td>\n",
       "      <td>0.356641</td>\n",
       "      <td>0.554342</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>0.319147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280574</td>\n",
       "      <td>0.389996</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.380873</td>\n",
       "      <td>2.639771</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.739098</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>0.629622</td>\n",
       "      <td>0.430374</td>\n",
       "      <td>0.284613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234373</td>\n",
       "      <td>0.306119</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565718</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.565193</td>\n",
       "      <td>0.315312</td>\n",
       "      <td>0.460520</td>\n",
       "      <td>0.108107</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.206084</td>\n",
       "      <td>3.555634</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.666639</td>\n",
       "      <td>0.318581</td>\n",
       "      <td>0.467526</td>\n",
       "      <td>0.338023</td>\n",
       "      <td>0.225223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165136</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diff_len  ratio_len   cos_sim  log_diff_len  test_id  unigram_jaccard  \\\n",
       "0         9   0.865672  0.895532      2.198335       -1         0.999950   \n",
       "1        37   0.593407  0.474331      3.611188       -1         0.666639   \n",
       "2        14   0.810811  0.380873      2.639771       -1         0.739098   \n",
       "3        13   0.793651  0.000000      2.565718       -1         0.565193   \n",
       "4        35   0.533333  0.206084      3.555634       -1         0.666639   \n",
       "\n",
       "   unigram_jaccard_all  unigram_jaccard_max  bigram_jaccard  \\\n",
       "0             0.463411             0.863623        0.906956   \n",
       "1             0.356641             0.554342        0.499993   \n",
       "2             0.386361             0.629622        0.430374   \n",
       "3             0.315312             0.460520        0.108107   \n",
       "4             0.318581             0.467526        0.338023   \n",
       "\n",
       "   bigram_jaccard_all          ...            trigram_jaccard_all  \\\n",
       "0            0.462806          ...                       0.462181   \n",
       "1            0.319147          ...                       0.280574   \n",
       "2            0.284613          ...                       0.234373   \n",
       "3            0.073394          ...                       0.000000   \n",
       "4            0.225223          ...                       0.165136   \n",
       "\n",
       "   trigram_jaccard_max  intersection_count  fuzz_qratio  fuzz_wratio  \\\n",
       "0             0.859362                   0           93           95   \n",
       "1             0.389996                   0           67           86   \n",
       "2             0.306119                   0           43           60   \n",
       "3             0.000000                   0            9           27   \n",
       "4             0.197800                   0           36           86   \n",
       "\n",
       "   fuzz_partial_ratio  fuzz_partial_token_set_ratio  \\\n",
       "0                 100                           100   \n",
       "1                  75                           100   \n",
       "2                  47                           100   \n",
       "3                  14                            33   \n",
       "4                  56                           100   \n",
       "\n",
       "   fuzz_partial_token_sort_ratio  fuzz_token_set_ratio  fuzz_token_sort_ratio  \n",
       "0                             88                   100                     93  \n",
       "1                             73                    86                     63  \n",
       "2                             71                    63                     63  \n",
       "3                             30                    28                     24  \n",
       "4                             67                    67                     47  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[predictors].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_leak = train_data[predictors].as_matrix()\n",
    "train_leak.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 22)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_leak = test_data[predictors].as_matrix()\n",
    "test_leak.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples = train_sequence_1.shape[0]\n",
    "#nb_samples = 1000\n",
    "msk = np.random.rand(nb_samples) < 0.8\n",
    "msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 30), (404290, 30), (404290, 22))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_all_1, X_all_2, X_all_3) = (train_sequence_1, train_sequence_2, train_leak)\n",
    "X_all_1.shape, X_all_2.shape, X_all_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290,), 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = np.array(train_labels)\n",
    "y_all.shape, y_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((323699, 30), (323699, 30), (323699, 22), (323699,))\n",
      "((80591, 30), (80591, 30), (80591, 22), (80591,))\n"
     ]
    }
   ],
   "source": [
    "X_train_1 = X_all_1[msk]\n",
    "X_train_2 = X_all_2[msk]\n",
    "X_train_3 = X_all_3[msk]\n",
    "\n",
    "X_valid_1 = X_all_1[~msk]\n",
    "X_valid_2 = X_all_2[~msk]\n",
    "X_valid_3 = X_all_3[~msk]\n",
    "\n",
    "y_train = y_all[msk]\n",
    "y_valid = y_all[~msk]\n",
    "\n",
    "print (X_train_1.shape, X_train_1.shape, X_train_3.shape, y_train.shape)\n",
    "print (X_valid_1.shape, X_valid_2.shape, X_valid_3.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(save_path + 'msk', msk)\n",
    "\n",
    "save_array(save_path + 'X_train_1', X_train_1)\n",
    "save_array(save_path + 'X_train_2', X_train_2)\n",
    "save_array(save_path + 'X_train_3', X_train_3)\n",
    "\n",
    "save_array(save_path + 'X_valid_1', X_valid_1)\n",
    "save_array(save_path + 'X_valid_2', X_valid_2)\n",
    "save_array(save_path + 'X_valid_3', X_valid_3)\n",
    "\n",
    "save_array(save_path + 'y_train', y_train)\n",
    "save_array(save_path + 'y_valid', y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((323699, 30), (323699, 30), (323699, 22), (323699,))\n",
      "((80591, 30), (80591, 30), (80591, 22), (80591,))\n"
     ]
    }
   ],
   "source": [
    "msk = load_array(save_path + 'msk')\n",
    "\n",
    "X_train_1 = load_array(save_path + 'X_train_1')\n",
    "X_train_2 = load_array(save_path + 'X_train_2')\n",
    "X_train_3 = load_array(save_path + 'X_train_3')\n",
    "\n",
    "X_valid_1 = load_array(save_path + 'X_valid_1')\n",
    "X_valid_2 = load_array(save_path + 'X_valid_2')\n",
    "X_valid_3 = load_array(save_path + 'X_valid_3')\n",
    "\n",
    "y_train = load_array(save_path + 'y_train')\n",
    "y_valid = load_array(save_path + 'y_valid')\n",
    "\n",
    "print (X_train_1.shape, X_train_1.shape, X_train_3.shape, y_train.shape)\n",
    "print (X_valid_1.shape, X_valid_2.shape, X_valid_3.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assign weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.30902834,  0.47200196,  1.30902834,  1.30902834,  0.47200196,\n",
       "        0.47200196,  1.30902834,  1.30902834,  1.30902834,  1.30902834])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_valid = np.ones(len(y_valid))\n",
    "weight_valid *= 0.472001959\n",
    "weight_valid[y_valid==0] = 1.309028344\n",
    "weight_valid[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {1.309028344, 0.472001959}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_ltsm = 200\n",
    "lstm_layer = LSTM(num_ltsm, dropout=0.3, recurrent_dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence_1 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_sequence_1 = embedding_layer(input_sequence_1)\n",
    "x1 = lstm_layer(embedding_sequence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence_2 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_sequence_2 = embedding_layer(input_sequence_2)\n",
    "x2 = lstm_layer(embedding_sequence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_input = Input(shape=(len(predictors),))\n",
    "\n",
    "x3 = Dense(256, kernel_initializer = 'he_normal')(dense_input)\n",
    "x3 = PReLU()(x3)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = Dropout(0.4)(x3)\n",
    "\n",
    "x3 = Dense(512, kernel_initializer = 'he_normal')(x3)\n",
    "x3 = PReLU()(x3)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = Dropout(0.2)(x3)\n",
    "\n",
    "x3 = Dense(512, kernel_initializer = 'he_normal')(x3)\n",
    "x3 = PReLU()(x3)\n",
    "x3 = Dropout(0.2)(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = concatenate([x1, x2, x3])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "\n",
    "pred_layer = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 22)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 256)           5888        input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)                (None, 256)           256         dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 256)           1024        p_re_lu_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 256)           0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 512)           131584      dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)                (None, 512)           512         dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 512)           2048        p_re_lu_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 512)           0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 512)           262656      dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 30, 300)       36150300    input_4[0][0]                    \n",
      "                                                                   input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)                (None, 512)           512         dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 200)           400800      embedding_2[0][0]                \n",
      "                                                                   embedding_2[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 512)           0           p_re_lu_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 912)           0           lstm_2[0][0]                     \n",
      "                                                                   lstm_2[1][0]                     \n",
      "                                                                   dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 912)           3648        concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 912)           0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 128)           116864      dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 128)           512         dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 128)           0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             129         dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 37,076,733\n",
      "Trainable params: 922,817\n",
      "Non-trainable params: 36,153,916\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_sequence_1, input_sequence_2, dense_input],\n",
    "              outputs=pred_layer\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "    ModelCheckpoint(model_path + 'glove_lstm_class_weight_leak_keras2.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323699 samples, validate on 80591 samples\n",
      "Epoch 1/200\n",
      "73s - loss: 0.4174 - acc: 0.7895 - val_loss: 1.2273 - val_acc: 0.5935\n",
      "Epoch 2/200\n",
      "75s - loss: 0.3422 - acc: 0.8354 - val_loss: 0.6349 - val_acc: 0.7281\n",
      "Epoch 3/200\n",
      "75s - loss: 0.3170 - acc: 0.8515 - val_loss: 0.2746 - val_acc: 0.8630\n",
      "Epoch 4/200\n",
      "75s - loss: 0.3032 - acc: 0.8600 - val_loss: 0.4147 - val_acc: 0.8031\n",
      "Epoch 5/200\n",
      "75s - loss: 0.2940 - acc: 0.8657 - val_loss: 0.2467 - val_acc: 0.8732\n",
      "Epoch 6/200\n",
      "75s - loss: 0.2898 - acc: 0.8671 - val_loss: 0.2544 - val_acc: 0.8717\n",
      "Epoch 7/200\n",
      "75s - loss: 0.2833 - acc: 0.8706 - val_loss: 0.2946 - val_acc: 0.8621\n",
      "Epoch 8/200\n",
      "76s - loss: 0.2800 - acc: 0.8724 - val_loss: 0.2199 - val_acc: 0.8755\n",
      "Epoch 9/200\n",
      "76s - loss: 0.2762 - acc: 0.8743 - val_loss: 0.2012 - val_acc: 0.8675\n",
      "Epoch 10/200\n",
      "75s - loss: 0.2720 - acc: 0.8764 - val_loss: 0.2871 - val_acc: 0.8645\n",
      "Epoch 11/200\n",
      "75s - loss: 0.2686 - acc: 0.8783 - val_loss: 0.2113 - val_acc: 0.8772\n",
      "Epoch 12/200\n",
      "75s - loss: 0.2654 - acc: 0.8797 - val_loss: 0.2158 - val_acc: 0.8778\n",
      "Epoch 13/200\n",
      "75s - loss: 0.2618 - acc: 0.8807 - val_loss: 0.3328 - val_acc: 0.8492\n",
      "Epoch 14/200\n",
      "75s - loss: 0.2587 - acc: 0.8824 - val_loss: 0.2198 - val_acc: 0.8807\n",
      "Epoch 15/200\n",
      "75s - loss: 0.2555 - acc: 0.8842 - val_loss: 0.2405 - val_acc: 0.8777\n",
      "Epoch 16/200\n",
      "75s - loss: 0.2522 - acc: 0.8858 - val_loss: 0.2384 - val_acc: 0.8788\n",
      "Epoch 17/200\n",
      "76s - loss: 0.2486 - acc: 0.8875 - val_loss: 0.1980 - val_acc: 0.8722\n",
      "Epoch 18/200\n",
      "75s - loss: 0.2461 - acc: 0.8891 - val_loss: 0.2608 - val_acc: 0.8726\n",
      "Epoch 19/200\n",
      "75s - loss: 0.2422 - acc: 0.8908 - val_loss: 0.2122 - val_acc: 0.8772\n",
      "Epoch 20/200\n",
      "75s - loss: 0.2396 - acc: 0.8916 - val_loss: 0.2400 - val_acc: 0.8766\n",
      "Epoch 21/200\n",
      "75s - loss: 0.2365 - acc: 0.8931 - val_loss: 0.2015 - val_acc: 0.8770\n",
      "Epoch 22/200\n",
      "75s - loss: 0.2336 - acc: 0.8948 - val_loss: 0.2296 - val_acc: 0.8801\n",
      "Epoch 23/200\n",
      "75s - loss: 0.2305 - acc: 0.8963 - val_loss: 0.3684 - val_acc: 0.8401\n",
      "Epoch 24/200\n",
      "75s - loss: 0.2290 - acc: 0.8970 - val_loss: 0.2920 - val_acc: 0.8691\n",
      "Epoch 25/200\n",
      "75s - loss: 0.2249 - acc: 0.8984 - val_loss: 0.2064 - val_acc: 0.8753\n",
      "Epoch 26/200\n",
      "75s - loss: 0.2225 - acc: 0.8998 - val_loss: 0.2170 - val_acc: 0.8815\n",
      "Epoch 27/200\n",
      "75s - loss: 0.2197 - acc: 0.9013 - val_loss: 0.2069 - val_acc: 0.8784\n",
      "Epoch 28/200\n",
      "75s - loss: 0.2175 - acc: 0.9021 - val_loss: 0.2020 - val_acc: 0.8677\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([X_train_1, X_train_2, X_train_3], y_train, \n",
    "                 validation_data=([X_valid_1, X_valid_2, X_valid_3], y_valid, weight_valid),\n",
    "                 class_weight=class_weight,\n",
    "                 batch_size=2048, epochs=200, verbose=2, shuffle=True,\n",
    "                 callbacks=callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(model_path + 'word2vec_lstm.h5')\n",
    "model.load_weights(model_path + 'glove_lstm_class_weight_leak_keras2.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323699 samples, validate on 80591 samples\n",
      "Epoch 1/200\n",
      "76s - loss: 0.3608 - acc: 0.8274 - val_loss: 0.3290 - val_acc: 0.8215\n",
      "Epoch 2/200\n",
      "76s - loss: 0.3559 - acc: 0.8300 - val_loss: 0.3257 - val_acc: 0.8204\n",
      "Epoch 3/200\n",
      "76s - loss: 0.3520 - acc: 0.8322 - val_loss: 0.3330 - val_acc: 0.8204\n",
      "Epoch 4/200\n",
      "76s - loss: 0.3475 - acc: 0.8344 - val_loss: 0.3283 - val_acc: 0.8242\n",
      "Epoch 5/200\n",
      "76s - loss: 0.3439 - acc: 0.8373 - val_loss: 0.3407 - val_acc: 0.8241\n",
      "Epoch 6/200\n",
      "77s - loss: 0.3397 - acc: 0.8397 - val_loss: 0.3005 - val_acc: 0.8255\n",
      "Epoch 7/200\n",
      "76s - loss: 0.3357 - acc: 0.8417 - val_loss: 0.3244 - val_acc: 0.8244\n",
      "Epoch 8/200\n",
      "76s - loss: 0.3309 - acc: 0.8443 - val_loss: 0.3412 - val_acc: 0.8251\n",
      "Epoch 9/200\n",
      "76s - loss: 0.3285 - acc: 0.8451 - val_loss: 0.3279 - val_acc: 0.8263\n",
      "Epoch 10/200\n",
      "76s - loss: 0.3245 - acc: 0.8485 - val_loss: 0.3190 - val_acc: 0.8291\n",
      "Epoch 11/200\n",
      "76s - loss: 0.3203 - acc: 0.8507 - val_loss: 0.3122 - val_acc: 0.8290\n",
      "Epoch 12/200\n",
      "76s - loss: 0.3181 - acc: 0.8518 - val_loss: 0.3445 - val_acc: 0.8271\n"
     ]
    }
   ],
   "source": [
    "model.optimizer = Adam(lr=0.0001)\n",
    "hist2 = model.fit([X_train_1, X_train_2, X_train_3], y_train, \n",
    "                 validation_data=([X_valid_1, X_valid_2, X_valid_3], y_valid, weight_valid),\n",
    "                 class_weight=class_weight,\n",
    "                 batch_size=2048, epochs=200, verbose=2, shuffle=True,\n",
    "                 callbacks=callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8862678])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = model.predict([X_train_1, X_train_2, X_train_3], batch_size=8192, verbose=2)\n",
    "sum(np.round(pred_train) == y_train.reshape(len(y_train), 1)) * 1.0 / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8722438])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid = model.predict([X_valid_1, X_valid_2, X_valid_3], batch_size=8192, verbose=2)\n",
    "sum(np.round(pred_valid) == y_valid.reshape(len(y_valid), 1)) * 1.0 / len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2345796, 30), (2345796, 30), (2345796, 22))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test_1, X_test_2, X_test_3) = (test_sequence_1, test_sequence_2, test_leak)\n",
    "X_test_1.shape, X_test_2.shape, X_test_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796/2345796 [==============================] - 120s   \n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict([X_test_1, X_test_2, X_test_3], batch_size=8192, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2345796, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0             1\n",
       "1        1             1\n",
       "2        2             1\n",
       "3        3             1\n",
       "4        4             1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(path + 'submission/sample_submission.csv')\n",
    "print df_submission.shape\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.169738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.296542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate\n",
       "0        0      0.007666\n",
       "1        1      0.066784\n",
       "2        2      0.169738\n",
       "3        3      0.002279\n",
       "4        4      0.296542"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission['is_duplicate'] = pred_test\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv(path + 'submission/quora_glove_lstm_class_weight_leak_keras2_20170615.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
